{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T12:57:00.011760727Z",
     "start_time": "2024-02-12T12:56:59.986387434Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)  # take environment variables from .env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022c4f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_debug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceef8075",
   "metadata": {},
   "source": [
    "# Ollama\n",
    "\n",
    "Local LLM, download from [ollama.com](https://ollama.com/download/linux)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "231b03d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "llm_llama = Ollama(model=\"llama2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dedba3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Why was the math book sad? Because it had too many problems! ðŸ˜‚\n"
     ]
    }
   ],
   "source": [
    "response = llm_llama.invoke(\"Tell me a joke\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba5e428a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the scarecrow win an award? Because he was outstanding in his field! ðŸ˜„"
     ]
    }
   ],
   "source": [
    "for chunk in llm_llama.stream(\"Tell me a joke\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07086400",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"When asked to tell a joke, only tell the joke and nothing else (no introduction, etc.).\"),\n",
    "    (\"user\", \"Tell me a joke about {input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "299deaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()  # The output of LLM will be a `message` -> parse it to a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d3642cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_llama = prompt | llm_llama | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "56fa104c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here's a joke for you:\n",
      "\n",
      "Why do programmers prefer dark mode?\n",
      "\n",
      "Because light attracts bugs.\n"
     ]
    }
   ],
   "source": [
    "response = chain_llama.invoke({\"input\": \"programmers\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b0d874cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the programmer break up with his girlfriend?\n",
      "She kept trying to fix her own problems, but he couldn't compile a solution."
     ]
    }
   ],
   "source": [
    "for chunk in chain_llama.stream({\"input\": \"programmers\"}):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538a9fcd",
   "metadata": {},
   "source": [
    "# OpenAI\n",
    "\n",
    "Create a key (<https://platform.openai.com/api-keys>) and set it in `.env`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "751b3cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "llm_openai = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "chain_openai = prompt | llm_openai | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "293a2bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why do programmers prefer dark mode? \n",
      "\n",
      "Because light attracts bugs!\n",
      "\n",
      "\n",
      "Tokens Used: 50\n",
      "\tPrompt Tokens: 37\n",
      "\tCompletion Tokens: 13\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $8.15e-05\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as token_usage:\n",
    "    \n",
    "    response = chain_openai.invoke({\"input\": \"programmers\"})\n",
    "    print(response)\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(token_usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4c955c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why do programmers prefer dark mode?\n",
      "\n",
      "Because light attracts bugs.\n",
      "\n",
      "Tokens Used: 0\n",
      "\tPrompt Tokens: 0\n",
      "\tCompletion Tokens: 0\n",
      "Successful Requests: 0\n",
      "Total Cost (USD): $0.0\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as token_usage:\n",
    "    \n",
    "    for chunk in chain_openai.stream({\"input\": \"programmers\"}):\n",
    "        print(chunk, end=\"\", flush=True)\n",
    "\n",
    "    print(\"\\n\")\n",
    "    # apparently, token counting does not work with streaming\n",
    "    print(token_usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dc298c",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation\n",
    "\n",
    "Use Chroma vectorstore to answer questions with context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a70cf51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ML-DEECo\\n\\nML-DEECo is a machine-learning-enabled component model for adaptive component architecture'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "\n",
    "# load the example document\n",
    "example_path = \"example_data/ML-DEECo_README.md\"\n",
    "loader = UnstructuredMarkdownLoader(example_path)\n",
    "docs = loader.load()\n",
    "\n",
    "docs[0].page_content[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "821281c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(page_content='ML-DEECo\\n\\nML-DEECo is a machine-learning-enabled component model for adaptive component architectures. It is based on DEECo component model, which features autonomic components and dynamic component coalitions (called ensembles). ML-DEECo allows exploiting machine learning in decisions about adapting component coalitions at runtime.', metadata={'source': 'example_data/ML-DEECo_README.md'})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# split it into chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(docs)\n",
    "\n",
    "print(len(docs))\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fa3747b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating vectorstore:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 13/14 [02:13<00:10, 10.28s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.chroma.Chroma at 0x7f38eb8e5ab0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "# from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from tqdm import tqdm\n",
    "\n",
    "# embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "embedding_function = OllamaEmbeddings()\n",
    "\n",
    "vectorstore = Chroma.from_documents([docs[0]], embedding_function)\n",
    "with tqdm(total=len(docs) - 1, desc=\"Creating vectorstore\") as progress_bar:\n",
    "    for d in docs[1:]:\n",
    "        vectorstore.add_documents([d])\n",
    "        progress_bar.update(1)  \n",
    "\n",
    "vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c238688b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'utility orders the components;\\n\\ncardinality sets the maximum (or both minimum and maximum) allowed number of components to be picked.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try a query\n",
    "query = \"What is utility?\"\n",
    "result = vectorstore.similarity_search(query)\n",
    "\n",
    "result[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm_llama, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7eb4e4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "60791dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:retrieval_chain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What is utility?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:retrieval_chain > 2:chain:RunnableAssign<context>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What is utility?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:retrieval_chain > 2:chain:RunnableAssign<context> > 3:chain:RunnableParallel<context>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What is utility?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:retrieval_chain > 2:chain:RunnableAssign<context> > 3:chain:RunnableParallel<context> > 4:chain:retrieve_documents] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What is utility?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:retrieval_chain > 2:chain:RunnableAssign<context> > 3:chain:RunnableParallel<context> > 4:chain:retrieve_documents > 5:chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What is utility?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:retrieval_chain > 2:chain:RunnableAssign<context> > 3:chain:RunnableParallel<context> > 4:chain:retrieve_documents > 5:chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"What is utility?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:retrieval_chain > 2:chain:RunnableAssign<context> > 3:chain:RunnableParallel<context> > 4:chain:retrieve_documents] [872ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:retrieval_chain > 2:chain:RunnableAssign<context> > 3:chain:RunnableParallel<context>] [877ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:retrieval_chain > 2:chain:RunnableAssign<context>] [878ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What is utility?\",\n",
      "  \"context\": [\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"document\",\n",
      "        \"Document\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"page_content\": \"utility orders the components;\\n\\ncardinality sets the maximum (or both minimum and maximum) allowed number of components to be picked.\",\n",
      "        \"metadata\": {\n",
      "          \"source\": \"example_data/ML-DEECo_README.md\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"document\",\n",
      "        \"Document\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"page_content\": \"The ML-DEECo framework provides abstractions for creating components and ensembles and assigning machine learning estimates to them. A simulation can then be run with the components and ensembles to observe behavior of the system and collect data for training the estimates. The trained estimate can then be used in the next run of the simulation.\",\n",
      "        \"metadata\": {\n",
      "          \"source\": \"example_data/ML-DEECo_README.md\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"document\",\n",
      "        \"Document\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"page_content\": \"class ChargingAssignment(Ensemble):\\n    # static role\\n    charger: Charger\\n\\n```\",\n",
      "        \"metadata\": {\n",
      "          \"source\": \"example_data/ML-DEECo_README.md\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"document\",\n",
      "        \"Document\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"page_content\": \"ML-DEECo is based on the DEECo component model (Bures et al.). We want to very briefly introduce the concepts of components and ensembles before describing the details of ML-DEECo usage.\\n\\nComponent\\n\\nComponents are autonomous agents in the system. Based on the knowledge they have, they can independently operate in the environment. In ML-DEECo, the components have an actuate method which is executed in every step of the simulation, and it thus comprises the behavior of the component.\\n\\nEnsemble\",\n",
      "        \"metadata\": {\n",
      "          \"source\": \"example_data/ML-DEECo_README.md\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:retrieval_chain > 7:chain:RunnableAssign<answer>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:retrieval_chain > 7:chain:RunnableAssign<answer> > 8:chain:RunnableParallel<answer>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:retrieval_chain > 7:chain:RunnableAssign<answer> > 8:chain:RunnableParallel<answer> > 9:chain:stuff_documents_chain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:retrieval_chain > 7:chain:RunnableAssign<answer> > 8:chain:RunnableParallel<answer> > 9:chain:stuff_documents_chain > 10:chain:format_inputs] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:retrieval_chain > 7:chain:RunnableAssign<answer> > 8:chain:RunnableParallel<answer> > 9:chain:stuff_documents_chain > 10:chain:format_inputs > 11:chain:RunnableParallel<context>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:retrieval_chain > 7:chain:RunnableAssign<answer> > 8:chain:RunnableParallel<answer> > 9:chain:stuff_documents_chain > 10:chain:format_inputs > 11:chain:RunnableParallel<context> > 12:chain:format_docs] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:retrieval_chain > 7:chain:RunnableAssign<answer> > 8:chain:RunnableParallel<answer> > 9:chain:stuff_documents_chain > 10:chain:format_inputs > 11:chain:RunnableParallel<context> > 12:chain:format_docs] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"utility orders the components;\\n\\ncardinality sets the maximum (or both minimum and maximum) allowed number of components to be picked.\\n\\nThe ML-DEECo framework provides abstractions for creating components and ensembles and assigning machine learning estimates to them. A simulation can then be run with the components and ensembles to observe behavior of the system and collect data for training the estimates. The trained estimate can then be used in the next run of the simulation.\\n\\nclass ChargingAssignment(Ensemble):\\n    # static role\\n    charger: Charger\\n\\n```\\n\\nML-DEECo is based on the DEECo component model (Bures et al.). We want to very briefly introduce the concepts of components and ensembles before describing the details of ML-DEECo usage.\\n\\nComponent\\n\\nComponents are autonomous agents in the system. Based on the knowledge they have, they can independently operate in the environment. In ML-DEECo, the components have an actuate method which is executed in every step of the simulation, and it thus comprises the behavior of the component.\\n\\nEnsemble\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:retrieval_chain > 7:chain:RunnableAssign<answer> > 8:chain:RunnableParallel<answer> > 9:chain:stuff_documents_chain > 10:chain:format_inputs > 11:chain:RunnableParallel<context>] [2ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"context\": \"utility orders the components;\\n\\ncardinality sets the maximum (or both minimum and maximum) allowed number of components to be picked.\\n\\nThe ML-DEECo framework provides abstractions for creating components and ensembles and assigning machine learning estimates to them. A simulation can then be run with the components and ensembles to observe behavior of the system and collect data for training the estimates. The trained estimate can then be used in the next run of the simulation.\\n\\nclass ChargingAssignment(Ensemble):\\n    # static role\\n    charger: Charger\\n\\n```\\n\\nML-DEECo is based on the DEECo component model (Bures et al.). We want to very briefly introduce the concepts of components and ensembles before describing the details of ML-DEECo usage.\\n\\nComponent\\n\\nComponents are autonomous agents in the system. Based on the knowledge they have, they can independently operate in the environment. In ML-DEECo, the components have an actuate method which is executed in every step of the simulation, and it thus comprises the behavior of the component.\\n\\nEnsemble\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:retrieval_chain > 7:chain:RunnableAssign<answer> > 8:chain:RunnableParallel<answer> > 9:chain:stuff_documents_chain > 10:chain:format_inputs] [2ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What is utility?\",\n",
      "  \"context\": \"utility orders the components;\\n\\ncardinality sets the maximum (or both minimum and maximum) allowed number of components to be picked.\\n\\nThe ML-DEECo framework provides abstractions for creating components and ensembles and assigning machine learning estimates to them. A simulation can then be run with the components and ensembles to observe behavior of the system and collect data for training the estimates. The trained estimate can then be used in the next run of the simulation.\\n\\nclass ChargingAssignment(Ensemble):\\n    # static role\\n    charger: Charger\\n\\n```\\n\\nML-DEECo is based on the DEECo component model (Bures et al.). We want to very briefly introduce the concepts of components and ensembles before describing the details of ML-DEECo usage.\\n\\nComponent\\n\\nComponents are autonomous agents in the system. Based on the knowledge they have, they can independently operate in the environment. In ML-DEECo, the components have an actuate method which is executed in every step of the simulation, and it thus comprises the behavior of the component.\\n\\nEnsemble\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:retrieval_chain > 7:chain:RunnableAssign<answer> > 8:chain:RunnableParallel<answer> > 9:chain:stuff_documents_chain > 13:prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What is utility?\",\n",
      "  \"context\": \"utility orders the components;\\n\\ncardinality sets the maximum (or both minimum and maximum) allowed number of components to be picked.\\n\\nThe ML-DEECo framework provides abstractions for creating components and ensembles and assigning machine learning estimates to them. A simulation can then be run with the components and ensembles to observe behavior of the system and collect data for training the estimates. The trained estimate can then be used in the next run of the simulation.\\n\\nclass ChargingAssignment(Ensemble):\\n    # static role\\n    charger: Charger\\n\\n```\\n\\nML-DEECo is based on the DEECo component model (Bures et al.). We want to very briefly introduce the concepts of components and ensembles before describing the details of ML-DEECo usage.\\n\\nComponent\\n\\nComponents are autonomous agents in the system. Based on the knowledge they have, they can independently operate in the environment. In ML-DEECo, the components have an actuate method which is executed in every step of the simulation, and it thus comprises the behavior of the component.\\n\\nEnsemble\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:retrieval_chain > 7:chain:RunnableAssign<answer> > 8:chain:RunnableParallel<answer> > 9:chain:stuff_documents_chain > 13:prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m{\n",
      "  \"lc\": 1,\n",
      "  \"type\": \"constructor\",\n",
      "  \"id\": [\n",
      "    \"langchain\",\n",
      "    \"prompts\",\n",
      "    \"chat\",\n",
      "    \"ChatPromptValue\"\n",
      "  ],\n",
      "  \"kwargs\": {\n",
      "    \"messages\": [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"Answer the following question based only on the provided context:\\n\\n<context>\\nutility orders the components;\\n\\ncardinality sets the maximum (or both minimum and maximum) allowed number of components to be picked.\\n\\nThe ML-DEECo framework provides abstractions for creating components and ensembles and assigning machine learning estimates to them. A simulation can then be run with the components and ensembles to observe behavior of the system and collect data for training the estimates. The trained estimate can then be used in the next run of the simulation.\\n\\nclass ChargingAssignment(Ensemble):\\n    # static role\\n    charger: Charger\\n\\n```\\n\\nML-DEECo is based on the DEECo component model (Bures et al.). We want to very briefly introduce the concepts of components and ensembles before describing the details of ML-DEECo usage.\\n\\nComponent\\n\\nComponents are autonomous agents in the system. Based on the knowledge they have, they can independently operate in the environment. In ML-DEECo, the components have an actuate method which is executed in every step of the simulation, and it thus comprises the behavior of the component.\\n\\nEnsemble\\n</context>\\n\\nQuestion: What is utility?\",\n",
      "          \"additional_kwargs\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:retrieval_chain > 7:chain:RunnableAssign<answer> > 8:chain:RunnableParallel<answer> > 9:chain:stuff_documents_chain > 14:llm:Ollama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Answer the following question based only on the provided context:\\n\\n<context>\\nutility orders the components;\\n\\ncardinality sets the maximum (or both minimum and maximum) allowed number of components to be picked.\\n\\nThe ML-DEECo framework provides abstractions for creating components and ensembles and assigning machine learning estimates to them. A simulation can then be run with the components and ensembles to observe behavior of the system and collect data for training the estimates. The trained estimate can then be used in the next run of the simulation.\\n\\nclass ChargingAssignment(Ensemble):\\n    # static role\\n    charger: Charger\\n\\n```\\n\\nML-DEECo is based on the DEECo component model (Bures et al.). We want to very briefly introduce the concepts of components and ensembles before describing the details of ML-DEECo usage.\\n\\nComponent\\n\\nComponents are autonomous agents in the system. Based on the knowledge they have, they can independently operate in the environment. In ML-DEECo, the components have an actuate method which is executed in every step of the simulation, and it thus comprises the behavior of the component.\\n\\nEnsemble\\n</context>\\n\\nQuestion: What is utility?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:retrieval_chain > 7:chain:RunnableAssign<answer> > 8:chain:RunnableParallel<answer> > 9:chain:stuff_documents_chain > 14:llm:Ollama] [43.55s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Based on the provided context, utility can be defined as the entity that orders or manages the components in the system. In other words, utility is responsible for allocating tasks or directives to the components, and ensuring that they operate correctly and efficiently within the environment.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama2\",\n",
      "          \"created_at\": \"2024-02-13T09:51:52.920970864Z\",\n",
      "          \"response\": \"\",\n",
      "          \"done\": true,\n",
      "          \"context\": [\n",
      "            518,\n",
      "            25580,\n",
      "            29962,\n",
      "            3532,\n",
      "            14816,\n",
      "            29903,\n",
      "            29958,\n",
      "            5299,\n",
      "            829,\n",
      "            14816,\n",
      "            29903,\n",
      "            6778,\n",
      "            13,\n",
      "            13,\n",
      "            29950,\n",
      "            7889,\n",
      "            29901,\n",
      "            673,\n",
      "            278,\n",
      "            1494,\n",
      "            1139,\n",
      "            2729,\n",
      "            871,\n",
      "            373,\n",
      "            278,\n",
      "            4944,\n",
      "            3030,\n",
      "            29901,\n",
      "            13,\n",
      "            13,\n",
      "            29966,\n",
      "            4703,\n",
      "            29958,\n",
      "            13,\n",
      "            329,\n",
      "            1793,\n",
      "            11299,\n",
      "            278,\n",
      "            7117,\n",
      "            29936,\n",
      "            13,\n",
      "            13,\n",
      "            7543,\n",
      "            979,\n",
      "            537,\n",
      "            6166,\n",
      "            278,\n",
      "            7472,\n",
      "            313,\n",
      "            272,\n",
      "            1716,\n",
      "            9212,\n",
      "            322,\n",
      "            7472,\n",
      "            29897,\n",
      "            6068,\n",
      "            1353,\n",
      "            310,\n",
      "            7117,\n",
      "            304,\n",
      "            367,\n",
      "            18691,\n",
      "            29889,\n",
      "            13,\n",
      "            13,\n",
      "            1576,\n",
      "            23158,\n",
      "            29899,\n",
      "            2287,\n",
      "            29923,\n",
      "            7967,\n",
      "            6890,\n",
      "            8128,\n",
      "            27086,\n",
      "            1953,\n",
      "            363,\n",
      "            4969,\n",
      "            7117,\n",
      "            322,\n",
      "            5662,\n",
      "            1590,\n",
      "            793,\n",
      "            322,\n",
      "            23188,\n",
      "            4933,\n",
      "            6509,\n",
      "            21875,\n",
      "            304,\n",
      "            963,\n",
      "            29889,\n",
      "            319,\n",
      "            17402,\n",
      "            508,\n",
      "            769,\n",
      "            367,\n",
      "            1065,\n",
      "            411,\n",
      "            278,\n",
      "            7117,\n",
      "            322,\n",
      "            5662,\n",
      "            1590,\n",
      "            793,\n",
      "            304,\n",
      "            14111,\n",
      "            6030,\n",
      "            310,\n",
      "            278,\n",
      "            1788,\n",
      "            322,\n",
      "            6314,\n",
      "            848,\n",
      "            363,\n",
      "            6694,\n",
      "            278,\n",
      "            21875,\n",
      "            29889,\n",
      "            450,\n",
      "            16370,\n",
      "            12678,\n",
      "            508,\n",
      "            769,\n",
      "            367,\n",
      "            1304,\n",
      "            297,\n",
      "            278,\n",
      "            2446,\n",
      "            1065,\n",
      "            310,\n",
      "            278,\n",
      "            17402,\n",
      "            29889,\n",
      "            13,\n",
      "            13,\n",
      "            1990,\n",
      "            678,\n",
      "            1191,\n",
      "            292,\n",
      "            7900,\n",
      "            10194,\n",
      "            29898,\n",
      "            29923,\n",
      "            1983,\n",
      "            6967,\n",
      "            1125,\n",
      "            13,\n",
      "            1678,\n",
      "            396,\n",
      "            2294,\n",
      "            6297,\n",
      "            13,\n",
      "            1678,\n",
      "            1373,\n",
      "            914,\n",
      "            29901,\n",
      "            2896,\n",
      "            914,\n",
      "            13,\n",
      "            13,\n",
      "            28956,\n",
      "            13,\n",
      "            13,\n",
      "            1988,\n",
      "            29899,\n",
      "            2287,\n",
      "            29923,\n",
      "            7967,\n",
      "            338,\n",
      "            2729,\n",
      "            373,\n",
      "            278,\n",
      "            5012,\n",
      "            29923,\n",
      "            7967,\n",
      "            4163,\n",
      "            1904,\n",
      "            313,\n",
      "            29933,\n",
      "            1973,\n",
      "            634,\n",
      "            394,\n",
      "            6250,\n",
      "            1334,\n",
      "            864,\n",
      "            304,\n",
      "            1407,\n",
      "            23359,\n",
      "            14944,\n",
      "            278,\n",
      "            22001,\n",
      "            310,\n",
      "            7117,\n",
      "            322,\n",
      "            5662,\n",
      "            1590,\n",
      "            793,\n",
      "            1434,\n",
      "            20766,\n",
      "            278,\n",
      "            4902,\n",
      "            310,\n",
      "            23158,\n",
      "            29899,\n",
      "            2287,\n",
      "            29923,\n",
      "            7967,\n",
      "            8744,\n",
      "            29889,\n",
      "            13,\n",
      "            13,\n",
      "            5308,\n",
      "            13,\n",
      "            13,\n",
      "            25503,\n",
      "            526,\n",
      "            28273,\n",
      "            681,\n",
      "            19518,\n",
      "            297,\n",
      "            278,\n",
      "            1788,\n",
      "            29889,\n",
      "            16564,\n",
      "            373,\n",
      "            278,\n",
      "            7134,\n",
      "            896,\n",
      "            505,\n",
      "            29892,\n",
      "            896,\n",
      "            508,\n",
      "            25499,\n",
      "            21994,\n",
      "            297,\n",
      "            278,\n",
      "            5177,\n",
      "            29889,\n",
      "            512,\n",
      "            23158,\n",
      "            29899,\n",
      "            2287,\n",
      "            29923,\n",
      "            7967,\n",
      "            29892,\n",
      "            278,\n",
      "            7117,\n",
      "            505,\n",
      "            385,\n",
      "            20331,\n",
      "            403,\n",
      "            1158,\n",
      "            607,\n",
      "            338,\n",
      "            8283,\n",
      "            297,\n",
      "            1432,\n",
      "            4331,\n",
      "            310,\n",
      "            278,\n",
      "            17402,\n",
      "            29892,\n",
      "            322,\n",
      "            372,\n",
      "            4550,\n",
      "            7199,\n",
      "            4637,\n",
      "            278,\n",
      "            6030,\n",
      "            310,\n",
      "            278,\n",
      "            4163,\n",
      "            29889,\n",
      "            13,\n",
      "            13,\n",
      "            29923,\n",
      "            1983,\n",
      "            6967,\n",
      "            13,\n",
      "            829,\n",
      "            4703,\n",
      "            29958,\n",
      "            13,\n",
      "            13,\n",
      "            16492,\n",
      "            29901,\n",
      "            1724,\n",
      "            338,\n",
      "            19725,\n",
      "            29973,\n",
      "            518,\n",
      "            29914,\n",
      "            25580,\n",
      "            29962,\n",
      "            13,\n",
      "            29933,\n",
      "            1463,\n",
      "            373,\n",
      "            278,\n",
      "            4944,\n",
      "            3030,\n",
      "            29892,\n",
      "            19725,\n",
      "            508,\n",
      "            367,\n",
      "            3342,\n",
      "            408,\n",
      "            278,\n",
      "            7855,\n",
      "            393,\n",
      "            11299,\n",
      "            470,\n",
      "            767,\n",
      "            1179,\n",
      "            278,\n",
      "            7117,\n",
      "            297,\n",
      "            278,\n",
      "            1788,\n",
      "            29889,\n",
      "            512,\n",
      "            916,\n",
      "            3838,\n",
      "            29892,\n",
      "            19725,\n",
      "            338,\n",
      "            14040,\n",
      "            363,\n",
      "            6643,\n",
      "            1218,\n",
      "            9595,\n",
      "            470,\n",
      "            1513,\n",
      "            3145,\n",
      "            304,\n",
      "            278,\n",
      "            7117,\n",
      "            29892,\n",
      "            322,\n",
      "            5662,\n",
      "            3864,\n",
      "            393,\n",
      "            896,\n",
      "            21994,\n",
      "            5149,\n",
      "            322,\n",
      "            29497,\n",
      "            2629,\n",
      "            278,\n",
      "            5177,\n",
      "            29889\n",
      "          ],\n",
      "          \"total_duration\": 43547923417,\n",
      "          \"load_duration\": 315554,\n",
      "          \"prompt_eval_count\": 294,\n",
      "          \"prompt_eval_duration\": 33487590000,\n",
      "          \"eval_count\": 57,\n",
      "          \"eval_duration\": 10059376000\n",
      "        },\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:retrieval_chain > 7:chain:RunnableAssign<answer> > 8:chain:RunnableParallel<answer> > 9:chain:stuff_documents_chain > 15:parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Based on the provided context, utility can be defined as the entity that orders or manages the components in the system. In other words, utility is responsible for allocating tasks or directives to the components, and ensuring that they operate correctly and efficiently within the environment.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:retrieval_chain > 7:chain:RunnableAssign<answer> > 8:chain:RunnableParallel<answer> > 9:chain:stuff_documents_chain > 15:parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Based on the provided context, utility can be defined as the entity that orders or manages the components in the system. In other words, utility is responsible for allocating tasks or directives to the components, and ensuring that they operate correctly and efficiently within the environment.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:retrieval_chain > 7:chain:RunnableAssign<answer> > 8:chain:RunnableParallel<answer> > 9:chain:stuff_documents_chain] [43.56s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Based on the provided context, utility can be defined as the entity that orders or manages the components in the system. In other words, utility is responsible for allocating tasks or directives to the components, and ensuring that they operate correctly and efficiently within the environment.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:retrieval_chain > 7:chain:RunnableAssign<answer> > 8:chain:RunnableParallel<answer>] [43.56s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"answer\": \"Based on the provided context, utility can be defined as the entity that orders or manages the components in the system. In other words, utility is responsible for allocating tasks or directives to the components, and ensuring that they operate correctly and efficiently within the environment.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:retrieval_chain > 7:chain:RunnableAssign<answer>] [43.56s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What is utility?\",\n",
      "  \"context\": [\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"document\",\n",
      "        \"Document\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"page_content\": \"utility orders the components;\\n\\ncardinality sets the maximum (or both minimum and maximum) allowed number of components to be picked.\",\n",
      "        \"metadata\": {\n",
      "          \"source\": \"example_data/ML-DEECo_README.md\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"document\",\n",
      "        \"Document\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"page_content\": \"The ML-DEECo framework provides abstractions for creating components and ensembles and assigning machine learning estimates to them. A simulation can then be run with the components and ensembles to observe behavior of the system and collect data for training the estimates. The trained estimate can then be used in the next run of the simulation.\",\n",
      "        \"metadata\": {\n",
      "          \"source\": \"example_data/ML-DEECo_README.md\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"document\",\n",
      "        \"Document\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"page_content\": \"class ChargingAssignment(Ensemble):\\n    # static role\\n    charger: Charger\\n\\n```\",\n",
      "        \"metadata\": {\n",
      "          \"source\": \"example_data/ML-DEECo_README.md\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"document\",\n",
      "        \"Document\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"page_content\": \"ML-DEECo is based on the DEECo component model (Bures et al.). We want to very briefly introduce the concepts of components and ensembles before describing the details of ML-DEECo usage.\\n\\nComponent\\n\\nComponents are autonomous agents in the system. Based on the knowledge they have, they can independently operate in the environment. In ML-DEECo, the components have an actuate method which is executed in every step of the simulation, and it thus comprises the behavior of the component.\\n\\nEnsemble\",\n",
      "        \"metadata\": {\n",
      "          \"source\": \"example_data/ML-DEECo_README.md\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"answer\": \"Based on the provided context, utility can be defined as the entity that orders or manages the components in the system. In other words, utility is responsible for allocating tasks or directives to the components, and ensuring that they operate correctly and efficiently within the environment.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:retrieval_chain] [44.44s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "Based on the provided context, utility can be defined as the entity that orders or manages the components in the system. In other words, utility is responsible for allocating tasks or directives to the components, and ensuring that they operate correctly and efficiently within the environment.\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"What is utility?\"})\n",
    "\n",
    "set_debug(True)\n",
    "print()\n",
    "print(response[\"answer\"])\n",
    "set_debug(False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
